# DIAGNOSTIC - API IA EN PANNE

**Date**: 26 Novembre 2025, 08:00  
**Statut**: üö® CRITIQUE - API IA NON FONCTIONNELLE

---

## R√âSUM√â EX√âCUTIF

L'agent IA du VPS DevOps Agent **ne r√©pond pas correctement** car l'API IA backend () est **compl√®tement en panne**.

### Sympt√¥mes observ√©s par l'utilisateur
- Les messages de l'utilisateur sont envoy√©s correctement
- L'interface affiche un indicateur de chargement "..."
- **Aucune r√©ponse n'arrive** (ou timeouts apr√®s 60 secondes)
- Les anciennes r√©ponses sont affich√©es, mais pas les nouvelles

---

## DIAGNOSTIC TECHNIQUE

### 1. Configuration actuelle
```
OPENAI_BASE_URL = https://ai.aenews.net
OPENAI_MODEL = gpt-4
OPENAI_MAX_TOKENS = 2000
OPENAI_TIMEOUT = 60000ms
```

### 2. √âtat de l'API IA

**Endpoint health** : `https://ai.aenews.net/api/health`
```json
{
  "status": "degraded",
  "services": {
    "ollama": "healthy",
    "vector_store": "unhealthy: ChromaDB temporairement d√©sactiv√© (API v1 d√©pr√©ci√©e)",
    "cache": "healthy"
  }
}
```

**Endpoint chat** : `https://ai.aenews.net/api/chat`
```json
{
  "error": "Internal Server Error",
  "message": "Une erreur interne s'est produite"
}
```

### 3. Tests effectu√©s

| Mod√®le | R√©sultat | Temps |
|--------|----------|-------|
| gpt-4 | ‚ùå Internal Server Error | 0.088s |
| phi3:mini | ‚ùå Internal Server Error | 0.079s |
| mistral | ‚ùå Internal Server Error | 0.075s |

### 4. Logs d'erreurs
```
[OpenAI Provider] API Error: timeout of 60000ms exceeded
‚ùå Agent chat error: Error: Request timeout. The model took too long to respond.
Error processing message: Error: Request timeout. The model took too long to respond.
```

---

## CAUSE RACINE

‚úÖ **Le probl√®me n'est PAS dans le frontend** (affichage OK)  
‚úÖ **Le probl√®me n'est PAS dans le backend** (route  OK)  
‚ùå **Le probl√®me EST dans l'API IA externe** : `https://ai.aenews.net`

L'API retourne syst√©matiquement une erreur 500 (Internal Server Error) pour toutes les requ√™tes vers `/api/chat`, quel que soit le mod√®le demand√©.

---

## SOLUTIONS POSSIBLES

### ‚úÖ SOLUTION 1 : R√©parer l'API https://ai.aenews.net (RECOMMAND√â)

**Actions n√©cessaires** :
1. Acc√©der au serveur h√©bergeant `ai.aenews.net`
2. V√©rifier les logs de l'API IA :
   ```bash
   pm2 logs ai-api
   # ou
   journalctl -u ai-api -f
   ```
3. Identifier pourquoi l'endpoint `/api/chat` retourne une erreur 500
4. Possibilit√©s :
   - Service Ollama arr√™t√© ou plant√©
   - Configuration incorrecte
   - Probl√®me de ChromaDB affectant toute l'API
   - Mod√®les non t√©l√©charg√©s
   - Erreur de connexion interne

5. Red√©marrer le service IA :
   ```bash
   pm2 restart ai-api
   # ou
   systemctl restart ollama
   ```

### ‚úÖ SOLUTION 2 : Utiliser une API OpenAI publique (Alternative)

Si `ai.aenews.net` ne peut pas √™tre r√©par√© imm√©diatement :

1. Obtenir une cl√© API OpenAI : https://platform.openai.com/api-keys
2. Modifier `/opt/vps-devops-agent/.env` :
   ```env
   OPENAI_BASE_URL=https://api.openai.com/v1
   OPENAI_API_KEY=sk-...votre-cl√©...
   OPENAI_MODEL=gpt-3.5-turbo
   OPENAI_MAX_TOKENS=500
   ```
3. Red√©marrer :
   ```bash
   pm2 restart vps-devops-agent
   ```

**‚ö†Ô∏è Co√ªt** : API OpenAI publique est payante (~$0.002 par requ√™te)

### ‚úÖ SOLUTION 3 : Installer Ollama localement

Si vous voulez un service IA gratuit et local :

1. Installer Ollama sur le serveur :
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ```

2. T√©l√©charger un mod√®le l√©ger :
   ```bash
   ollama pull phi3:mini
   # ou
   ollama pull mistral:7b
   ```

3. Modifier `/opt/vps-devops-agent/.env` :
   ```env
   OPENAI_BASE_URL=http://localhost:11434/v1
   OPENAI_MODEL=phi3:mini
   OPENAI_MAX_TOKENS=500
   ```

4. Red√©marrer :
   ```bash
   pm2 restart vps-devops-agent
   ```

**‚úÖ Avantages** : Gratuit, rapide, pas de limite
**‚ö†Ô∏è Inconv√©nients** : Consomme ~4GB RAM, mod√®les moins performants que GPT-4

---

## ACTIONS IMM√âDIATES RECOMMAND√âES

### Priorit√© HAUTE üî¥
1. **V√©rifier l'√©tat du serveur `ai.aenews.net`**
   - Acc√©der au serveur
   - Consulter les logs : `pm2 logs ai-api` ou `journalctl -u ai-api`
   - Identifier l'erreur 500

2. **Red√©marrer le service IA**
   ```bash
   pm2 restart ai-api
   # ou
   systemctl restart ollama
   ```

3. **Tester l'API apr√®s red√©marrage**
   ```bash
   curl -X POST https://ai.aenews.net/api/chat \
     -H 'Content-Type: application/json' \
     -d '{"model":"phi3:mini","messages":[{"role":"user","content":"test"}]}'
   ```

### Priorit√© MOYENNE üü°
4. **Si l'API reste en panne** : Installer Ollama localement (Solution 3)

### Priorit√© BASSE üü¢
5. **Ajouter un monitoring** pour d√©tecter les pannes d'API automatiquement
6. **Configurer un fallback** vers une API alternative en cas de panne

---

## VALIDATION

Apr√®s correction, tester avec :

```bash
cd /opt/vps-devops-agent
bash test-agent.sh
```

**Attendu** :
- ‚úÖ R√©ponse de l'agent en < 30 secondes
- ‚úÖ Pas de timeout
- ‚úÖ Messages complets et coh√©rents

---

## CONTACT

- **Serveur API IA** : https://ai.aenews.net
- **Serveur DevOps Agent** : https://devops.aenews.net
- **Dashboard** : https://devops.aenews.net/dashboard.html

